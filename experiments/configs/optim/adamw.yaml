name: "${.optimizer}_${.learning_rate}_${.weight_decay}_${.scheduler}_${.grad_clip}"
optimizer: "adamw"
betas: [0.9, 0.999]
learning_rate: 1e-5
weight_decay: 0.0
warmup: 0
scheduler: "cosine"
grad_clip: 1

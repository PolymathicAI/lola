{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from einops import rearrange\n",
    "from functools import partial\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "\n",
    "from lola.autoencoder import get_autoencoder\n",
    "from lola.data import field_preprocess, get_well_inputs, get_well_multi_dataset\n",
    "from lola.diffusion import get_denoiser\n",
    "from lola.emulation import decode_traj, emulate_diffusion, emulate_rollout, encode_traj\n",
    "from lola.plot import animate_fields, draw_psd\n",
    "\n",
    "plt.rcParams[\"animation.ffmpeg_path\"] = \"/mnt/sw/nix/store/fz8y69w4c97lcgv1wwk03bd4yh4zank7-ffmpeg-full-6.0-bin/bin/ffmpeg\"  # fmt: off\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runpath = Path(\"/mnt/ceph/users/frozet/lola/runs/ldm/TODO\")\n",
    "cfg = OmegaConf.load(runpath / \"config.yaml\")\n",
    "cfg.ae = OmegaConf.load(runpath / \"autoencoder/config.yaml\").ae\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_well_multi_dataset(\n",
    "    path=\"/mnt/ceph/users/polymathic/the_well/datasets\",\n",
    "    physics=cfg.dataset.physics,\n",
    "    split=\"valid\",\n",
    "    steps=-1,\n",
    "    include_filters=cfg.dataset.include_filters,\n",
    "    augment=[\"log_scalars\"],\n",
    ")\n",
    "\n",
    "preprocess = partial(\n",
    "    field_preprocess,\n",
    "    mean=torch.as_tensor(cfg.dataset.stats.mean, device=device),\n",
    "    std=torch.as_tensor(cfg.dataset.stats.std, device=device),\n",
    "    transform=cfg.dataset.transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, label = get_well_inputs(dataset[42], device=device)\n",
    "x = x[0 : 33 : cfg.trajectory.stride]\n",
    "x = preprocess(x)\n",
    "x = rearrange(x, \"L H W C -> C L H W\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder = get_autoencoder(\n",
    "    pix_channels=dataset.metadata.n_fields,\n",
    "    **cfg.ae,\n",
    ")\n",
    "\n",
    "autoencoder.load_state_dict(\n",
    "    torch.load(runpath / \"autoencoder/state.pth\", weights_only=True, map_location=device)\n",
    ")\n",
    "autoencoder.to(device)\n",
    "autoencoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = encode_traj(autoencoder, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shape = (z.shape[0], cfg.trajectory.length, *z.shape[2:])\n",
    "\n",
    "denoiser = get_denoiser(\n",
    "    shape=shape,\n",
    "    label_features=label.numel(),\n",
    "    masked=True,\n",
    "    **cfg.denoiser,\n",
    ")\n",
    "\n",
    "denoiser.load_state_dict(torch.load(runpath / \"state.pth\", weights_only=True, map_location=device))\n",
    "denoiser.to(device)\n",
    "denoiser.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in denoiser.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emulate(mask, y):\n",
    "    return emulate_diffusion(denoiser, mask, y, label=label, algorithm=\"lms\", steps=16)\n",
    "\n",
    "\n",
    "z_hat = emulate_rollout(\n",
    "    emulate,\n",
    "    z,\n",
    "    window=cfg.trajectory.length,\n",
    "    rollout=z.shape[1],\n",
    "    context=1,\n",
    "    overlap=1,\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_hat = decode_traj(autoencoder, z_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = animate_fields(x, x_hat, fields=cfg.dataset.fields, figsize=(3.2, 3.2))\n",
    "display(animation)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = draw_psd(x[:, -1], x_hat[:, -1], fields=cfg.dataset.fields)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flex",
   "language": "python",
   "name": "flex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
